{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "fa7bf7db-ee23-4316-a9de-320e83b83487",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os,math,sys,torch,re,numpy as np\n",
    "from types import SimpleNamespace as ns\n",
    "from collections import namedtuple\n",
    "import os\n",
    "import torch\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "16b953af-a802-4310-9520-2dd4d672c53e",
   "metadata": {},
   "outputs": [],
   "source": [
    "DEBUG_MODE = True\n",
    "if DEBUG_MODE: os.environ['NUMBA_ENABLE_CUDASIM'] = '1'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "cea3ec94-dfd0-4b0b-93b8-4f8833a7366e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numba\n",
    "from numba import cuda\n",
    "if not DEBUG_MODE:\n",
    "    from numba.cuda import as_cuda_array as ca"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "db9599be-9196-4f34-931b-e4dff4990fb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.insert(0, '..')\n",
    "from utils import show_img,load_cuda,cuda_begin,cdiv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d9722e70-c04a-4b4e-b377-b8629344d41c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "def get_sig(fname, src):\n",
    "    res = re.findall(rf'^(.+\\s+{fname}\\(.*?\\))\\s*{{?\\s*$', src, re.MULTILINE)\n",
    "    return res[0]+';' if res else None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0c71e72f-6070-4d52-a85c-797e7b086a53",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "cuda_src = cuda_begin + r'''\n",
    "#include <cuda_runtime.h>\n",
    "#include <sstream> // Include the stringstream header\n",
    "\n",
    "std::string get_device_prop() {\n",
    "    cudaDeviceProp devProp;\n",
    "    cudaError_t cudaStatus = cudaGetDeviceProperties(&devProp, 0);\n",
    "    if (cudaStatus != cudaSuccess) {\n",
    "        return \"Failed to get device properties\"; // Handle error appropriately\n",
    "    }\n",
    "\n",
    "    std::ostringstream stream; // Use ostringstream for formatting the string\n",
    "\n",
    "    // Extract device properties\n",
    "    int maxThreads = devProp.maxThreadsPerBlock;\n",
    "    size_t totalGlobalMem = devProp.totalGlobalMem;\n",
    "    size_t sharedMemPerBlock = devProp.sharedMemPerBlock;\n",
    "    int regsPerBlock = devProp.regsPerBlock;\n",
    "    int warpSize = devProp.warpSize;\n",
    "    int maxThreadsPerMultiProcessor = devProp.maxThreadsPerMultiProcessor;\n",
    "    size_t sharedMemPerMultiprocessor = devProp.sharedMemPerMultiprocessor;\n",
    "    int regsPerMultiprocessor = devProp.regsPerMultiprocessor;\n",
    "\n",
    "    // Format the string with device properties\n",
    "    stream << maxThreads << \", \" << totalGlobalMem << \", \" << sharedMemPerBlock\n",
    "           << \", \" << regsPerBlock << \", \" << warpSize << \", \" \n",
    "           << maxThreadsPerMultiProcessor << \", \" << sharedMemPerMultiprocessor \n",
    "           << \", \" << regsPerMultiprocessor;\n",
    "\n",
    "    return stream.str(); // Return the formatted string\n",
    "}\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "31b4ae01-c312-45da-83be-b51b6ff753ca",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'1024, 25438126080, 49152, 65536, 32, 1536, 102400, 65536'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fname = 'get_device_prop'\n",
    "# cpp_src = get_sig(fname, cuda_src)\n",
    "cpp_src = \"std::string get_device_prop();\"\n",
    "print_module = load_cuda(cuda_src, cpp_src, [fname])\n",
    "print_module.get_device_prop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "772512fa-2293-4418-a113-2e4b1148f720",
   "metadata": {},
   "outputs": [],
   "source": [
    "shared_mem_per_sm = 102400\n",
    "shared_mem_per_block = 49152"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "559c2fac-2c52-492f-9e3a-fca70ba5931e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2.0833333333333335"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "shared_mem_per_sm/shared_mem_per_block"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a49f0687-93d5-4b87-8b50-ad918750aa42",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "768"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max_threads_per_sm = 1536\n",
    "approx_block_size = int(max_threads_per_sm / np.floor(shared_mem_per_sm/shared_mem_per_block)); approx_block_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ce10446e-3b6d-4707-873e-47d8b0d967e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "assert approx_block_size * 2 * np.dtype(\"float32\").itemsize <= shared_mem_per_sm, \"Max possible shared mem per block exceeded!\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "157c64fe-df0b-4913-b1de-38baf0756b4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "max_threads_per_block = 1024\n",
    "assert approx_block_size <= max_threads_per_block, f\"Have more threads per block {approx_block_size} > {max_threads_per_block}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "09d90c2c-f2ac-4e68-b8cd-ed638e517083",
   "metadata": {},
   "outputs": [],
   "source": [
    "warp_size = 32\n",
    "assert approx_block_size % warp_size == 0, \"Block size is not divisible by warp which will cause underutilization!\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "148513f5-ceca-466f-8452-2862141ce9d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# for registers and occupancy: https://docs.nvidia.com/cuda/archive/10.2/cuda-occupancy-calculator/index.html"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "325de6e1-5a98-43ff-be81-5318a8cecdf6",
   "metadata": {},
   "source": [
    "### Rectangle Tile Matmul\n",
    "\n",
    "**Note:** Using rectangle tiles either wide or tall is causing issues with synchronization and race conditions if we want to implement something efficient. Otherwise solutions would require a more than needed shared memory usage and/or idle threads.\n",
    "\n",
    "So for matmul with tall and wide matrices, such as the MNIST example, where A=50,000 x 768 and B= 768 x 10 we will use a block with dim3(x,1,1) and process a single row or single col per block.\n",
    "\n",
    "- Case 1: `A=50,000 x 768 and B= 768 x 10`, each thread produce an output row.\n",
    "- Case 2: `A=10 x 768 and B= 768 x 50,000`, each thread produce an output col."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "79403309-0e59-44f9-9f12-9ff8a1920b11",
   "metadata": {},
   "outputs": [],
   "source": [
    "@cuda.jit\n",
    "def matmul_flat_tile_numba(m, n, out, tw):\n",
    "\n",
    "    cbi,cbd,tid = cuda.blockIdx,cuda.blockDim,cuda.threadIdx\n",
    "    tx,ty = tid.x,tid.y\n",
    "\n",
    "    h,k  = m.shape\n",
    "    k2,w = n.shape\n",
    "    \n",
    "    ms = cuda.shared.array(0, dtype=np.dtype(\"float32\"))\n",
    "    \n",
    "    r = cbi.x\n",
    "\n",
    "    for ph in range(math.ceil(k/tw)):\n",
    "                \n",
    "        # fill shared mem\n",
    "        idx = ph*tw\n",
    "        ms[tx] = m[r, idx+tx] if r<h and idx+tx<k else 0.\n",
    "        cuda.syncthreads()\n",
    "\n",
    "        for c in range(w):        \n",
    "            # dot-product and accumulate\n",
    "            p = 0\n",
    "            for i in range(tw):\n",
    "                 p += ms[i] * n[idx+tx,c]\n",
    "            out[r,c] = p\n",
    "        cuda.syncthreads()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "7645258e-841c-482d-92f0-64c89a45df94",
   "metadata": {},
   "outputs": [],
   "source": [
    "def matmul_2d_numba(m, n, tw):\n",
    "    h,k  = m.shape\n",
    "    k2,w = n.shape\n",
    "    assert k==k2, \"Size mismatch!\"\n",
    "    out = torch.zeros(h, w, dtype=m.dtype).cuda()\n",
    "    \n",
    "    dtype_size = np.dtype(\"float32\").itemsize\n",
    "    dyn_shared_mem_size = tw * dtype_size\n",
    "    \n",
    "    blocks = (h,)\n",
    "    tpb = (tw,)\n",
    "    \n",
    "    if DEBUG_MODE:\n",
    "        matmul_flat_tile_numba[blocks, tpb, 0, dyn_shared_mem_size](m, n, out, tw) \n",
    "    else:\n",
    "        matmul_flat_tile_numba[blocks, tpb, 0, dyn_shared_mem_size](ca(m), ca(n), ca(out), tw) \n",
    "    return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "7340a533-4f4d-4fc0-bb8a-d440ad37ef5d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[ 0.,  1.,  2.,  3.],\n",
       "         [ 4.,  5.,  6.,  7.],\n",
       "         [ 8.,  9., 10., 11.]], device='cuda:0'),\n",
       " tensor([[ 0.,  1.,  2.,  3.,  4.,  5.],\n",
       "         [ 6.,  7.,  8.,  9., 10., 11.],\n",
       "         [12., 13., 14., 15., 16., 17.],\n",
       "         [18., 19., 20., 21., 22., 23.]], device='cuda:0'))"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m1s = torch.arange(12).view(3,4).float().contiguous().cuda()\n",
    "m2 = torch.arange(24).view(4,6).float().contiguous().cuda()\n",
    "m1s,m2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "2540a264-4998-413b-a9db-c33fb30f5b55",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 60.,  65.,  70.,  75.,  80.,  85.],\n",
       "        [234., 247., 260., 273., 286., 299.],\n",
       "        [252., 399., 420., 315., 336., 357.]], device='cuda:0')"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "matmul_2d_numba(m1s,m2,tw=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "86b19d9f-0534-40ba-b77a-5144ab27a0b1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 84.,  90.,  96., 102., 108., 114.],\n",
       "        [228., 250., 272., 294., 316., 338.],\n",
       "        [372., 410., 448., 486., 524., 562.]], device='cuda:0')"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m1s@m2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "cca7b88b-fd2b-45c7-be69-7c520fefd759",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.allclose(matmul_2d_numba(m1s,m2,tw=4), m1s@m2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "202255ae-edcd-468d-9b0a-6297a38b7246",
   "metadata": {},
   "source": [
    "### CUDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "767caeb6-4ec8-4b80-a1c4-bf1b3df49a06",
   "metadata": {},
   "outputs": [],
   "source": [
    "A = torch.randn(50_000, 768).contiguous().cuda()\n",
    "B = torch.randn(768, 10).contiguous().cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "939aa09d-b695-4ca6-a0cb-bfc117d2ec56",
   "metadata": {},
   "outputs": [],
   "source": [
    "cuda_src = cuda_begin + r'''\n",
    "template<int tw>\n",
    "__global__ void matmul_k(float *m, float *n, float *out, int h, int w, int k) {\n",
    "    int tc=threadIdx.x, tr=threadIdx.y;\n",
    "    int r=blockIdx.y*blockDim.y+tr, c=blockIdx.x*blockDim.x+tc;\n",
    "    extern __shared__ float ms[];\n",
    "    float *ns = &ms[tw*tw];\n",
    "\n",
    "    float p = 0.0f;\n",
    "    for (int ph = 0; ph < cdiv(k,tw); ++ph) {\n",
    "        int idx = ph*tw;\n",
    "        ms[tr*tw + tc] = r<h && idx+tc<k ? m[ tc+idx + r*k ] : 0.0f;\n",
    "        ns[tr*tw + tc] = c<w && idx+tr<k ? n[(tr+idx)*w + c] : 0.0f;\n",
    "        __syncthreads();\n",
    "        for (int i=0; i<tw; ++i) p += ms[tr*tw + i] * ns[tw*i + tc];\n",
    "        __syncthreads();\n",
    "    }\n",
    "    if (r<h && c<w) out[r*w + c] = p;\n",
    "}\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f12666de-8be1-4643-b239-c0ecbe70ea59",
   "metadata": {},
   "outputs": [],
   "source": [
    "cuda_src += r'''\n",
    "torch::Tensor matmul_sq_tile(torch::Tensor m, torch::Tensor n, int TW) {\n",
    "    CHECK_INPUT(m); CHECK_INPUT(n);\n",
    "    int h=m.size(0), w=n.size(1), k=m.size(1);\n",
    "    TORCH_CHECK(k==n.size(0), \"Size mismatch!\");\n",
    "    auto output = torch::zeros({h, w}, m.options());\n",
    "    \n",
    "    //int TW = 8; // TODO: Calculate this dynamically\n",
    "    \n",
    "    size_t size = TW*TW*2 * sizeof(float) + 1;\n",
    "    dim3 tpb(TW,TW);\n",
    "    dim3 blocks(cdiv(w, tpb.x), cdiv(h, tpb.y));\n",
    "\n",
    "    auto f = [&](auto kf) { kf<<<blocks, tpb, size>>>(\n",
    "        m.data_ptr<float>(), n.data_ptr<float>(), output.data_ptr<float>(), h, w, k);\n",
    "    };\n",
    "    switch(TW) {\n",
    "        case 8: f(matmul_k<8>); break;\n",
    "        case 16: f(matmul_k<16>); break;\n",
    "        case 32: f(matmul_k<32>); break;\n",
    "        default: break;\n",
    "    }\n",
    "    C10_CUDA_KERNEL_LAUNCH_CHECK();\n",
    "    return output;\n",
    "}\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20c562a6-5216-4e9e-a0ad-32aabf8089f7",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "fname = 'matmul_sq_tile'\n",
    "cpp_src = get_sig(fname, cuda_src)\n",
    "module = load_cuda(cuda_src, cpp_src, [fname])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "27de432b-33c2-4661-ae14-7ad8f244b8c9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "699 µs ± 12.2 µs per loop (mean ± std. dev. of 7 runs, 10 loops each)\n"
     ]
    }
   ],
   "source": [
    "%%timeit -n 10\n",
    "module.matmul_sq_tile(A,B,8)\n",
    "torch.cuda.synchronize()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "c4663618-6aad-404f-86ef-7208f586c56d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "489 µs ± 8.62 µs per loop (mean ± std. dev. of 7 runs, 10 loops each)\n"
     ]
    }
   ],
   "source": [
    "%%timeit -n 10\n",
    "module.matmul_sq_tile(A,B,16)\n",
    "torch.cuda.synchronize()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "796e24af-9ac4-4f8f-8faa-1731c72f749d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.03 ms ± 36.6 µs per loop (mean ± std. dev. of 7 runs, 10 loops each)\n"
     ]
    }
   ],
   "source": [
    "%%timeit -n 10\n",
    "module.matmul_sq_tile(A,B,32)\n",
    "torch.cuda.synchronize()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "9cd3d1fd-0be1-4964-b8a1-6e1f2f45b9a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "cuda_src = cuda_begin + r'''\n",
    "template<int tw>\n",
    "__global__ void matmul_k(float *m, float *n, float *out, int h, int w, int k) {\n",
    "    int tc=threadIdx.x, tr=threadIdx.y;\n",
    "    int r=blockIdx.y*blockDim.y+tr, c=blockIdx.x*blockDim.x+tc;\n",
    "    extern __shared__ float ms[];\n",
    "    float *ns = &ms[tw*tw];\n",
    "\n",
    "    float p = 0.0f;\n",
    "    for (int ph = 0; ph < cdiv(k,tw); ++ph) {\n",
    "        int idx = ph*tw;\n",
    "        ms[tr*tw + tc] = r<h && idx+tc<k ? m[ tc+idx + r*k ] : 0.0f;\n",
    "        ns[tr*tw + tc] = c<w && idx+tr<k ? n[(tr+idx)*w + c] : 0.0f;\n",
    "        __syncthreads();\n",
    "        for (int i=0; i<tw; ++i) p += ms[tr*tw + i] * ns[tw*i + tc];\n",
    "        __syncthreads();\n",
    "    }\n",
    "    if (r<h && c<w) out[r*w + c] = p;\n",
    "}\n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7fff5093-e160-4d0d-b2b3-472fa22f1ea3",
   "metadata": {},
   "source": [
    "**Note:** This is much slower !!! Because shared memory is repeatedly filled for ms, instead of using it multiple times. fix `matmul_flat_tile_numba`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9e921a0-13fd-46ae-9ea3-d0abe80ba0a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "@cuda.jit\n",
    "def matmul_flat_tile_numba(m, n, out, tw):\n",
    "\n",
    "    cbi,cbd,tid = cuda.blockIdx,cuda.blockDim,cuda.threadIdx\n",
    "    tx,ty = tid.x,tid.y\n",
    "\n",
    "    h,k  = m.shape\n",
    "    k2,w = n.shape\n",
    "    \n",
    "    shar = cuda.shared.array(0, dtype=np.dtype(\"float32\"))\n",
    "    ms,ns = shar[:tw],shar[tw:]\n",
    "    \n",
    "    r = cbi.x\n",
    "\n",
    "    for c in range(w):\n",
    "        p = 0\n",
    "        for ph in range(math.ceil(k/tw)):\n",
    "                    \n",
    "            # fill shared mem\n",
    "            idx = ph*tw\n",
    "            \n",
    "            # transposed and aligned for dot-product\n",
    "            ms[tx] = m[r, idx+tx] if r<h and idx+tx<k else 0.\n",
    "            ns[tx] = n[idx+tx, c] if c<w and idx+tx<k else 0.\n",
    "            cuda.syncthreads()\n",
    "\n",
    "            # dot-product and accumulate\n",
    "            for i in range(tw):\n",
    "                p += ms[i] * ns[i]\n",
    "            cuda.syncthreads()\n",
    "            \n",
    "        if r < h and c < w: out[r,c] = p"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4be616f-8e31-44f5-98d8-3738c81586db",
   "metadata": {},
   "outputs": [],
   "source": [
    "@cuda.jit\n",
    "def matmul_flat_tile_numba(m, n, out, tw):\n",
    "\n",
    "    cbi,cbd,tid = cuda.blockIdx,cuda.blockDim,cuda.threadIdx\n",
    "    tx,ty = tid.x,tid.y\n",
    "\n",
    "    h,k  = m.shape\n",
    "    k2,w = n.shape\n",
    "    \n",
    "    ms = cuda.shared.array(0, dtype=np.dtype(\"float32\"))\n",
    "    \n",
    "    r = cbi.x\n",
    "\n",
    "    for ph in range(math.ceil(k/tw)):\n",
    "                \n",
    "        # fill shared mem\n",
    "        idx = ph*tw\n",
    "        ms[tx] = m[r, idx+tx] if r<h and idx+tx<k else 0.\n",
    "        cuda.syncthreads()\n",
    "\n",
    "        for c in range(w):        \n",
    "            # dot-product and accumulate\n",
    "            p = 0\n",
    "            for i in range(tw):\n",
    "                 p += ms[i] * n[idx+tx,c]\n",
    "            out[r,c] = p\n",
    "        cuda.syncthreads()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "16d40738-6450-41c3-a857-e287b6a285ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "cuda_src = cuda_begin + r'''\n",
    "template<int tw>\n",
    "__global__ void matmul_k(float *m, float *n, float *out, int h, int w, int k) {\n",
    "    \n",
    "    int tx=threadIdx.x, ty=threadIdx.y, r=blockIdx.x;\n",
    "    \n",
    "    extern __shared__ float ms[];\n",
    "\n",
    "    for (int ph = 0; ph < cdiv(k,tw); ++ph) {\n",
    "        int idx = ph*tw;\n",
    "        ms[tx] = r<h && idx+tx<k ? m[r*k + idx + tx] : 0.0f;\n",
    "        __syncthreads();\n",
    "        for (int c=0; c<w; ++c){\n",
    "            for (int i=0; i<tw; ++i) out[r*w + c] += ms[i] * n[(idx+tx)*w + c];\n",
    "        }\n",
    "        __syncthreads();\n",
    "    }\n",
    "    \n",
    "}\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "cc53614a-cdd8-4ab9-8d5a-9b1758879cd3",
   "metadata": {},
   "outputs": [],
   "source": [
    "cuda_src += r'''\n",
    "torch::Tensor matmul_flat_tile(torch::Tensor m, torch::Tensor n, int TW) {\n",
    "    CHECK_INPUT(m); CHECK_INPUT(n);\n",
    "    int h=m.size(0), w=n.size(1), k=m.size(1);\n",
    "    TORCH_CHECK(k==n.size(0), \"Size mismatch!\");\n",
    "    auto output = torch::zeros({h, w}, m.options());\n",
    "\n",
    "    size_t size = TW * sizeof(float) + 1;\n",
    "    dim3 tpb(TW);\n",
    "    dim3 blocks(h);\n",
    "\n",
    "    auto f = [&](auto kf) { kf<<<blocks, tpb, size>>>(\n",
    "        m.data_ptr<float>(), n.data_ptr<float>(), output.data_ptr<float>(), h, w, k);\n",
    "    };\n",
    "    switch(TW) {\n",
    "        case 256: f(matmul_k<256>); break;\n",
    "        case 512: f(matmul_k<512>); break;\n",
    "        case 768: f(matmul_k<768>); break;\n",
    "        default: break;\n",
    "    }\n",
    "    C10_CUDA_KERNEL_LAUNCH_CHECK();\n",
    "    return output;\n",
    "}\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "c3fb4506-5003-42e9-b1f8-410e9e06091c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "fname = 'matmul_flat_tile'\n",
    "cpp_src = get_sig(fname, cuda_src)\n",
    "flat_module = load_cuda(cuda_src, cpp_src, [fname])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45ab7ff8-df5e-4bd4-b2dc-9a98eac5c4b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "assert torch.allclose(flat_module.matmul_flat_tile(A,B,768), A@B, atol=1e-4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "9ad437c0-349f-4939-b8bf-aeb2bd48d4f4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[  -7.4253,   18.9958,  -31.8680,  ...,   -9.9729,   60.7632,\n",
       "           43.9456],\n",
       "        [  12.7517,   -4.6914,   -7.9195,  ...,   23.2486, -181.1063,\n",
       "            6.4379],\n",
       "        [  -4.8458,   -2.0506,   17.1899,  ...,  -37.1760,   44.4268,\n",
       "           19.3395],\n",
       "        ...,\n",
       "        [  -7.7356,   15.3391,   25.3848,  ...,    7.1080,    7.9670,\n",
       "           -9.5791],\n",
       "        [   8.8504,  -18.9655,    9.4784,  ...,  123.9788,  -38.5527,\n",
       "           11.5962],\n",
       "        [   2.3148,    4.7446,    7.9802,  ...,   -6.2798,    2.5232,\n",
       "          -11.4697]], device='cuda:0')"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "flat_module.matmul_flat_tile(A,B,768)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a50ac3a-4ebb-4b71-85c2-84549f8ea6e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%timeit -n 10\n",
    "flat_module.matmul_flat_tile(A,B,768)\n",
    "torch.cuda.synchronize()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57c73a2f-d61e-46f9-873e-ab9ff3b5472e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8a2ec62-db52-499f-9f92-20c4ef5a0bd8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f4b48d9-e58d-4f86-94a8-313e7a897005",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42dc2755-458e-4cd5-bbf5-cbe0c6a999e3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a71a35de-4a26-45e0-abe7-0fc4e1395ebb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8cbd412-39b2-43e2-8b77-6e36356e5b1b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72fc8eeb-da07-4fb5-8d7d-eb1ee0c7e52e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b9739ab-975d-4b35-b23d-25e09f2b3162",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9d381fc-dec2-45bc-8f4c-21d75293ac3c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c36f299d-185a-4901-824d-b64be032d446",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f013639f-c63a-4345-8e1d-80a35a3fe4b0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d8f0a08-8541-4ad5-ae85-d87b4422d093",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db37e51b-d086-4672-8c99-521de61952bf",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b7146e8-cd7c-4b95-acda-710fe9fd7d46",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72e2d716-b6f2-4dc0-b2eb-df41d8a1ae7c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7292e076-028c-40c8-81f5-a7e22cba8f82",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74128d0a-2f49-4c55-8ed8-efbe0066f017",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fde5b0e3-9729-411b-8d9a-3266539efcdc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84073b0f-a872-428a-b7b3-37695825ab34",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1121a00d-e7a2-480b-9f44-4f5447fcc9e9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e46a98e-991b-41dc-882c-6fbbd71cf25c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8955ba9d-b35c-449f-99c4-fbc208c2dd46",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1224d69-4d9d-4da3-8893-55d986a5ecbe",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "226d157c-9161-414a-81e7-3d795d6c1002",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d177a5b-4fc7-418f-953f-8239578fe830",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a60b7eb1-d69d-40a5-aa06-a44449585571",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e021dcb-b517-4318-b83b-604ac85c878f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a79817f3-857a-4e3b-bab6-59652f45e70a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5d755f7-4970-4850-9c48-c06a2d7c4209",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb1a0d5c-d929-4b22-8bda-190da25851d6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3f50e04-8c1b-4fbb-8b8c-0a20112d8dea",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03463a86-34e3-40af-9180-a85c79e53f14",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
